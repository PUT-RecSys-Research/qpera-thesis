[build-system]
requires = ["flit_core >=3.2,<4"]
build-backend = "flit_core.buildapi"

[project]
name = "qpera"
version = "1.0.0"
description = "Quality of Personalization, Explainability and Robustness of Recommendation Algorithms"
long_description = """
An in-depth analysis of three main families of recommendation algorithms 
(collaborative filtering, content-based, reinforcement learning) in terms of:
- Resilience to data-related stresses
- Resistance to anonymization  
- Ability to generate explanations
- Ethical risks associated with implementation

Addressing EU AI Act compliance and ethical risk taxonomy through extensive 
experiments across different recommendation scenarios and datasets.
"""
authors = [
  { name = "Julia Podsadna & Bartosz ChwiÅ‚kowski" },
]
license = { file = "LICENSE" }
readme = "README.md"
keywords = [
    "recommendation-systems",
    "reinforcement-learning", 
    "privacy",
    "explainability",
    "personalization",
    "ai-ethics"
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Science/Research",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
]
requires-python = ">=3.9"

dependencies = [
    "easydict",
    "kaggle",
    "recommenders",
    "cornac",
    "scikit-surprise",
    "mlflow",
    "category-encoders",
    "pandera",
    "fastapi",
    "gunicorn",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "ruff>=0.1.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "jupyter>=1.0.0",
    "jupyterlab>=4.0.0",
    "ipykernel>=6.0.0",
]

ml-extra = [
    "torch>=1.12.0",
    "torchvision>=0.13.0",
    "tensorboard>=2.10.0",
    "optuna>=3.0.0",
]

all = ["ppera[dev,ml-extra]"]

[tool.ruff]
line-length = 160
target-version = "py39"
exclude = [
    ".git",
    "__pycache__",
    "build",
    "dist",
    "*.egg-info",
    "qpera/rl_tmp",
]

[tool.ruff.lint]
select = [
    "E",
    "F",
    "W",
    "I",
]

ignore = [
    "E731",
    "C901",
    "E501",
    "E203",
    "E402",
    "F401",
    "F841",
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401", "F403"]
"tests/*" = ["ALL"]
"qpera/rl_*.py" = ["E501", "C901", "E402", "F841", "E722"]
"qpera/*_train*.py" = ["E501", "C901", "E402", "F841"]
"qpera/*_test*.py" = ["E501", "C901", "E402", "F841"]
"qpera/main.py" = ["E501", "C901"]
"qpera/datasets_*.py" = ["E501", "F841"]

[tool.ruff.lint.isort]
known_first_party = ["qpera"]
force_single_line = false
split-on-trailing_comma = true
combine-as-imports = true

[tool.black]
line-length = 160
target-version = ["py39"]
skip-string-normalization = true
force-exclude = '''
/(
    qpera/rl_tmp
    | \.git
    | \.mypy_cache
    | \.pytest_cache
    | \.ruff_cache
)/
'''

[tool.isort]
profile = "black"
line_length = 160
known_first_party = ["qpera"]
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
skip_glob = ["qpera/rl_tmp/*"]
float_to_top = true
force_sort_within_sections = false

[tool.pytest.ini_options]
minversion = "7.0"
testpaths = ["tests"]
addopts = [
    "--strict-markers",
    "--cov=qpera",
    "--cov-report=term-missing",
]
markers = [
    "slow: marks tests as slow",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
]

[tool.coverage.run]
source = ["qpera"]
omit = [
    "*/tests/*",
    "*/test_*",
    "setup.py",
    "qpera/rl_tmp/*",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
]