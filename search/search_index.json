{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Quality of Personalization, Explainability and Robustness of Recommendation Algorithms","text":"<p>A Master's Thesis Project for evaluating recommendation algorithms on Quality, Personalization, Explainability, and Robustness.</p>"},{"location":"#overview","title":"\ud83d\udcd6 Overview","text":"<p>This project provides a in-depth analysis of recommendation algorithms, focusing on their resilience to data stress, resistance to anonymization, explainability, and the ethical risks associated with their implementation. The research is particularly relevant given the recently adopted EU AI Act and the Omnibus Directive.</p> <p>Built on Open Source</p> <p>This project extends and unifies implementations from the Microsoft Recommenders library and PGPR, providing a custom dataset loader and evaluation pipeline for comparative analysis.</p>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<p>Use the cards below to navigate to the section you need.</p> <ul> <li> <p> Getting Started</p> <p>Complete installation guide and first experiment setup.</p> <p> Get Started</p> </li> <li> <p> Run Experiments</p> <p>Configure and execute algorithm comparisons.</p> <p> Run Experiments</p> </li> <li> <p> Results &amp; Analysis</p> <p>Research findings, publications, and how to cite this work.</p> <p> See Results</p> </li> <li> <p> Architecture</p> <p>Code structure, design patterns, and extension points.</p> <p> Explore Architecture</p> </li> </ul>"},{"location":"#research-questions","title":"\u2753 Research Questions","text":"<p>This research addresses the following key questions:</p> <ol> <li>Robustness Analysis: How do different recommendation algorithm families compare in terms of resilience to data anonymization and perturbation techniques?</li> <li>Privacy-Personalization Trade-off: What is the relationship between recommendation accuracy, personalization quality, and user privacy preservation?</li> <li>Explainability Assessment: To what extent can each algorithm generate meaningful explanations for its recommendations?</li> <li>Ethical Risk Evaluation: How can ethical risks be identified, measured, and mitigated in accordance with EU AI Act requirements?</li> </ol>"},{"location":"#contributing-support","title":"\ud83e\udd1d Contributing &amp; Support","text":"<ul> <li>\ud83d\udc1b Bug Reports: GitHub Issues</li> <li>\ud83d\udcac Questions &amp; Ideas: GitHub Discussions</li> <li>\ud83d\udee0\ufe0f Code Contributions: See our Contributing Guidelines</li> </ul>"},{"location":"acknowledgments/","title":"Acknowledgments","text":"<p>We extend our sincere gratitude to all individuals and organizations who contributed to the success of this research project.</p>"},{"location":"acknowledgments/#supervision-guidance","title":"\ud83c\udf93 Supervision &amp; Guidance","text":"<ul> <li>Prof. Miko\u0142aj Morzy: Our supervisor, whose expertise in data mining and recommendation systems provided invaluable direction. His insights into algorithm evaluation and ethical considerations were fundamental to shaping this work.</li> <li>Prof. Jerzy Nawrocki: For the \"Pre-diploma and Diploma seminar\" and the materials, which provided essential insights and foundational knowledge.</li> </ul>"},{"location":"acknowledgments/#foundational-works-resources","title":"\ud83d\udee0\ufe0f Foundational Works &amp; Resources","text":"<p>This project builds upon the work of the open-source community. We are particularly grateful for:</p> <ul> <li>Microsoft Recommenders Team: For their comprehensive library that served as the foundation for our collaborative filtering implementations.</li> <li>PGPR Authors: For making their policy gradient recommendation framework available, enabling our reinforcement learning experiments.</li> <li>Kaggle Community &amp; MovieLens Project: For providing the high-quality, accessible datasets that were crucial for our evaluation.</li> </ul>"},{"location":"acknowledgments/#tools-infrastructure","title":"\ud83d\udcbb Tools &amp; Infrastructure","text":"<p>The development and documentation of this project were made possible by several key tools:</p> <ul> <li>MLflow: For experiment tracking and ensuring reproducible research.</li> <li>Material for MkDocs: For enabling this professional documentation.</li> <li>GitHub: For hosting our open-source implementation and enabling collaborative development.</li> <li>Cookiecutter Data Science: For the project template that provided a solid foundation for reproducible research.</li> </ul>"},{"location":"acknowledgments/#institutional-support","title":"\ud83c\udfdb\ufe0f Institutional Support","text":"<p>We thank Poznan University of Technology for providing the academic environment, computational resources, and institutional support necessary for conducting this research.</p>"},{"location":"acknowledgments/#personal-acknowledgments","title":"\ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 Personal Acknowledgments","text":"<p>Finally, we extend our heartfelt thanks to our families and friends for their unwavering support, encouragement, and understanding throughout this intensive research period.</p>"},{"location":"api/","title":"API Reference","text":"<p>This document provides detailed API documentation for the QPERA project components. It is generated based on the source code to ensure accuracy.</p>"},{"location":"api/#1-main-entry-point","title":"1. Main Entry Point","text":""},{"location":"api/#qperamain","title":"<code>qpera.main</code>","text":"<p>This is the central orchestration module for running all experiments. It parses command-line arguments to select and execute predefined experiment configurations.</p> <p>Key Function: <pre><code>def main()\n</code></pre> The main CLI entry point that parses arguments (<code>--algo</code>, <code>--dataset</code>, <code>--privacy</code>, etc.) to select and run experiment configurations from the <code>EXPERIMENT_CONFIGS</code> list.</p> <p>Experiment Configuration: The core of this module is the <code>EXPERIMENT_CONFIGS</code> list, which defines the matrix of experiments to be run. Each entry is a dictionary specifying the algorithm, module, function, and dataset.</p> <pre><code># Located in qpera/main.py\nEXPERIMENT_CONFIGS = [\n    {\"algo\": \"CBF\", \"module\": CBF, \"func\": \"cbf_experiment_loop\", \"dataset\": \"movielens\"},\n    {\"algo\": \"CF\", \"module\": CF, \"func\": \"cf_experiment_loop\", \"dataset\": \"movielens\"},\n    {\"algo\": \"RL\", \"module\": RL, \"func\": \"rl_experiment_loop\", \"dataset\": \"movielens\", \"rows\": 14000},\n    # ... and more combinations for amazonsales and postrecommendations\n]\n</code></pre>"},{"location":"api/#2-algorithm-implementations","title":"2. Algorithm Implementations","text":"<p>This section details the core recommendation algorithm experiment loops.</p>"},{"location":"api/#collaborative-filtering","title":"Collaborative Filtering","text":""},{"location":"api/#qperacf","title":"<code>qpera.CF</code>","text":"<p>Implements the collaborative filtering experiment loop using the Cornac library.</p> <p>Main Function: <pre><code>def cf_experiment_loop(\n    TOP_K: int,\n    dataset: str,\n    want_col: list,\n    # ... and other parameters for privacy/personalization\n) -&gt; None\n</code></pre> - Core Model: <code>cornac.models.BPR</code> (Bayesian Personalized Ranking). - Hyperparameters: <code>k=100</code> (factors), <code>max_iter=100</code>, <code>learning_rate=0.01</code>. - Metrics Computed: Includes precision, recall, F1, MRR, MAE, RMSE, NDCG, coverage, and personalization scores.</p>"},{"location":"api/#content-based-filtering","title":"Content-Based Filtering","text":""},{"location":"api/#qperacbf","title":"<code>qpera.CBF</code>","text":"<p>Implements the content-based filtering experiment loop.</p> <p>Main Function: <pre><code>def cbf_experiment_loop(\n    TOP_K: int,\n    dataset: str,\n    want_col: list,\n    # ... (same parameters as cf_experiment_loop)\n) -&gt; None\n</code></pre> - Core Model: A custom <code>TfidfRecommender</code> that uses TF-IDF vectorization on item features. - Features: Primarily uses the <code>genres</code> column for similarity calculation.</p>"},{"location":"api/#reinforcement-learning","title":"Reinforcement Learning","text":"<p>The RL implementation is distributed across several modules, orchestrated by <code>RL.py</code>.</p>"},{"location":"api/#qperarl","title":"<code>qpera.RL</code>","text":"<p>This module contains the main experiment loop for the Reinforcement Learning approach.</p> <p>Main Function: <pre><code>def rl_experiment_loop(\n    TOP_K: int,\n    dataset: str,\n    want_col: list,\n    # ... (same parameters as cf_experiment_loop)\n) -&gt; None\n</code></pre> - Orchestration: This function coordinates the entire RL pipeline: data preprocessing, knowledge graph creation, TransE model training, agent training, and evaluation.</p>"},{"location":"api/#3-data-processing","title":"3. Data Processing","text":""},{"location":"api/#dataset-loading","title":"Dataset Loading","text":""},{"location":"api/#qperadatasets_loader","title":"<code>qpera.datasets_loader</code>","text":"<p>Handles loading and basic preprocessing of datasets.</p> <p>Core Function: <pre><code>def loader(dataset: str, want_col: list, num_rows: int = None, seed: int = 42) -&gt; pd.DataFrame\n</code></pre> - Supported Datasets: <code>\"movielens\"</code>, <code>\"amazonsales\"</code>, <code>\"postrecommendations\"</code>. - Functionality: Loads data from CSV, samples if <code>num_rows</code> is specified, and selects columns based on <code>want_col</code>.</p>"},{"location":"api/#data-manipulation","title":"Data Manipulation","text":""},{"location":"api/#qperadata_manipulation","title":"<code>qpera.data_manipulation</code>","text":"<p>Contains functions to apply privacy and personalization transformations to the data.</p> <p>Core Functions: <pre><code>def hide_data_in_dataframe(data, hide_type, columns_to_hide, fraction_to_hide, records_to_hide, seed)\n</code></pre> Simulates privacy scenarios by hiding or altering data.</p> <p><pre><code>def change_items_in_dataframe(all, data, fraction_to_change, change_rating, seed)\n</code></pre> Simulates personalization scenarios by modifying user interaction data.</p>"},{"location":"api/#4-evaluation-tracking","title":"4. Evaluation &amp; Tracking","text":""},{"location":"api/#metrics","title":"Metrics","text":""},{"location":"api/#qperametrics","title":"<code>qpera.metrics</code>","text":"<p>A collection of custom and third-party evaluation metrics.</p> <p>Accuracy &amp; Ranking Metrics: - <code>precision_at_k</code>, <code>recall_at_k</code>, <code>f1</code>, <code>mrr</code>, <code>ndcg_at_k</code></p> <p>Coverage &amp; Diversity Metrics: - <code>user_coverage</code>, <code>item_coverage</code> - <code>personalization</code> (based on Jaccard similarity) - <code>intra_list_similarity</code></p> <p>Error Metrics: - <code>mae</code>, <code>rmse</code> (from Microsoft Recommenders)</p>"},{"location":"api/#mlflow-integration","title":"MLflow Integration","text":""},{"location":"api/#qperalog_mlflow","title":"<code>qpera.log_mlflow</code>","text":"<p>Handles all logging of experiments to the MLflow Tracking server.</p> <p>Main Function: <pre><code>def log_mlflow(\n    dataset: str,\n    top_k: pd.DataFrame,\n    metrics: dict,\n    # ... many other parameters for logging context\n) -&gt; None\n</code></pre> - Experiment Naming: Organizes runs into experiments like <code>\"MLflow Collaborative Filtering\"</code>. - Logged Artifacts: Logs parameters, all computed metrics, model files, and dataset samples to ensure full reproducibility. - Representative Sampling: Uses a <code>_create_representative_sample</code> function to log a stratified sample of the data for inspection.</p>"},{"location":"api/#5-reinforcement-learning-components","title":"5. Reinforcement Learning Components","text":"<p>This section details the modules specific to the RL-based recommendation approach.</p>"},{"location":"api/#knowledge-graph-utilities","title":"Knowledge Graph Utilities","text":""},{"location":"api/#qperarl_utils","title":"<code>qpera.rl_utils</code>","text":"<p>Provides constants and helper functions for the RL pipeline.</p> <p>Key Constants: - <code>DATASET_DIR</code>, <code>TMP_DIR</code>: Define file paths for datasets and temporary RL artifacts. - <code>KG_RELATION</code>: A dictionary defining the structure and valid connections between entities in the knowledge graph. - <code>PATH_PATTERN</code>: Defines valid multi-hop paths for generating recommendations and explanations. - Entity and relation name constants (<code>USERID</code>, <code>WATCHED</code>, etc.).</p> <p>Key Functions: - <code>save_embed</code>, <code>load_embed</code>: Save/load trained embeddings. - <code>save_kg</code>, <code>load_kg</code>: Save/load the constructed knowledge graph. - <code>save_labels</code>, <code>load_labels</code>: Save/load user-item interaction labels for training/testing. - <code>cleanup_dataset_files</code>: Removes temporary files generated during the RL pipeline.</p>"},{"location":"api/#rl-environment","title":"RL Environment","text":""},{"location":"api/#qperarl_kg_env","title":"<code>qpera.rl_kg_env</code>","text":"<p>Defines the reinforcement learning environment built on the knowledge graph.</p> <p>Core Classes: - <code>KGState</code>: A class to construct the state representation for the agent, combining user embeddings with path history. - <code>BatchKGEnvironment</code>: Manages the agent's interaction with the knowledge graph, including state transitions and rewards, for a batch of users.</p>"},{"location":"api/#rl-agent-evaluation","title":"RL Agent &amp; Evaluation","text":""},{"location":"api/#qperarl_test_agent","title":"<code>qpera.rl_test_agent</code>","text":"<p>Contains the core PPO agent and evaluation logic.</p> <p>Core Classes &amp; Functions: - <code>ActorCritic(nn.Module)</code>: The policy and value network for the PPO agent. - <code>batch_beam_search(...)</code>: Performs beam search to generate recommendation paths in the knowledge graph. - <code>run_evaluation(...)</code>: Evaluates the generated paths against test data and computes metrics.</p>"},{"location":"architecture/","title":"Project Architecture","text":"<p>This document explains the codebase structure, core components, and design patterns of the QPERA project.</p>"},{"location":"architecture/#1-project-structure","title":"1. Project Structure","text":"<p>The repository is organized using a structure inspired by the Cookiecutter Data Science template to ensure reproducibility and maintainability.</p> <pre><code>.\n\u251c\u2500\u2500 Makefile            # Convenience commands for setup, testing, and execution\n\u251c\u2500\u2500 README.md           # Main project documentation for GitHub\n\u251c\u2500\u2500 environment.yml     # Conda environment specification\n\u251c\u2500\u2500 mkdocs.yml          # Configuration for the documentation site\n\u251c\u2500\u2500 pyproject.toml      # Python project configuration (PEP 621)\n\u2502\n\u251c\u2500\u2500 datasets/           # \ud83d\uddc4\ufe0f Raw datasets downloaded from sources (e.g., Kaggle)\n\u2502   \u251c\u2500\u2500 MovieLens/\n\u2502   \u251c\u2500\u2500 AmazonSales/\n\u2502   \u2514\u2500\u2500 PostRecommendations/\n\u2502\n\u251c\u2500\u2500 docs/               # \ud83d\udcda Project documentation source files\n\u2502   \u251c\u2500\u2500 api.md\n\u2502   \u251c\u2500\u2500 architecture.md\n\u2502   \u2514\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 qpera/              # \ud83d\udc0d Main source code package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 main.py         # Main CLI entry point and experiment orchestrator\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 datasets/       # \ud83d\udcbe Processed &amp; cached datasets (e.g., merge_file.csv)\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 rl_tmp/         # \u2699\ufe0f Cached artifacts for the RL pipeline (e.g., kg.pkl)\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 # --- Data Handling ---\n\u2502   \u251c\u2500\u2500 datasets_loader.py\n\u2502   \u251c\u2500\u2500 data_manipulation.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 # --- Core Algorithms ---\n\u2502   \u251c\u2500\u2500 CBF.py\n\u2502   \u251c\u2500\u2500 CF.py\n\u2502   \u251c\u2500\u2500 RL.py           # Reinforcement Learning orchestrator\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 # --- Reinforcement Learning Components ---\n\u2502   \u251c\u2500\u2500 rl_preprocess.py\n\u2502   \u251c\u2500\u2500 rl_knowledge_graph.py\n\u2502   \u251c\u2500\u2500 rl_kg_env.py\n\u2502   \u251c\u2500\u2500 rl_transe_model.py\n\u2502   \u251c\u2500\u2500 rl_train_agent.py\n\u2502   \u251c\u2500\u2500 rl_test_agent.py\n\u2502   \u2514\u2500\u2500 rl_utils.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 # --- Utilities &amp; Tooling ---\n\u2502   \u251c\u2500\u2500 metrics.py\n\u2502   \u2514\u2500\u2500 log_mlflow.py\n\u2502\n\u251c\u2500\u2500 references/         # \ud83d\udcc4 Research papers, articles, and reference materials\n\u2502\n\u2514\u2500\u2500 reports/            # \ud83d\udcca Generated analysis, figures, and results\n    \u2514\u2500\u2500 plots/          # \ud83d\udcc8 Visualizations (e.g., precision/recall plots)\n</code></pre>"},{"location":"architecture/#2-core-components","title":"2. Core Components","text":"<p>This section details the key modules within the <code>qpera/</code> source directory.</p>"},{"location":"architecture/#main-entry-point-qperamainpy","title":"Main Entry Point (<code>qpera/main.py</code>)","text":"<p>The central orchestration script that manages experiment execution based on command-line arguments. It iterates through predefined experiment configurations to run tests for different algorithms, datasets, and scenarios (clear, privacy, personalization).</p>"},{"location":"architecture/#dataset-loading-qperadatasets_loaderpy","title":"Dataset Loading (<code>qpera/datasets_loader.py</code>)","text":"<p>Implements a unified, class-based system for loading and preprocessing datasets. - <code>BaseDatasetLoader</code>: An abstract base class defining the loading interface. - Concrete Loaders: <code>MovieLensDataset</code>, <code>AmazonSalesDataset</code>, and <code>PostRecommendationsDataset</code> handle the specifics of each data source, including column normalization, data cleaning, and merging.</p>"},{"location":"architecture/#algorithm-implementations","title":"Algorithm Implementations","text":"<p>Each algorithm is encapsulated in its own module with a consistent experiment loop function.</p> <ul> <li>Collaborative Filtering (<code>qpera/CF.py</code>): Implements a BPR (Bayesian Personalized Ranking) model using the Cornac library.</li> <li>Content-Based Filtering (<code>qpera/CBF.py</code>): Implements a <code>TfidfRecommender</code> using item features (e.g., genres) and cosine similarity.</li> <li>Reinforcement Learning (<code>qpera/RL.py</code>): Orchestrates the complex, multi-stage RL pipeline, including knowledge graph creation, model training, and evaluation.</li> </ul>"},{"location":"architecture/#reinforcement-learning-pipeline","title":"Reinforcement Learning Pipeline","text":"<p>The RL approach is broken down into several specialized modules.</p> <ul> <li>Preprocessing (<code>qpera/rl_preprocess.py</code>): Extracts entities (users, items, genres) and relations from the raw data to build a knowledge graph.</li> <li>KG Environment (<code>qpera/rl_kg_env.py</code>): Defines the <code>BatchKGEnvironment</code> where the agent interacts with the knowledge graph, managing state transitions and rewards.</li> <li>TransE Model (<code>qpera/rl_transe_model.py</code>): An implementation of the TransE algorithm to learn low-dimensional embeddings for entities and relations in the knowledge graph.</li> <li>Agent (<code>qpera/rl_train_agent.py</code>): Contains the <code>ActorCritic</code> model (PPO agent) that learns a policy for navigating the knowledge graph to find recommendations.</li> <li>Inference (<code>qpera/rl_test_agent.py</code>): Uses a <code>batch_beam_search</code> function to generate recommendation paths from the trained agent and knowledge graph.</li> </ul>"},{"location":"architecture/#data-manipulation-qperadata_manipulationpy","title":"Data Manipulation (<code>qpera/data_manipulation.py</code>)","text":"<p>Provides functions to simulate different scenarios for robustness testing. - <code>hide_information_in_dataframe</code>: Simulates privacy attacks by removing or obscuring values in specified columns or entire records. - <code>change_items_in_dataframe</code>: Simulates personalization shifts by substituting items in a user's history based on global popularity.</p>"},{"location":"architecture/#evaluation-framework","title":"Evaluation Framework","text":"<ul> <li>Metrics (<code>qpera/metrics.py</code>): A comprehensive collection of metrics, including accuracy (<code>precision_at_k</code>, <code>ndcg_at_k</code>), coverage (<code>user_coverage</code>), and diversity (<code>personalization</code>, <code>intra_list_similarity</code>).</li> <li>MLflow Logging (<code>qpera/log_mlflow.py</code>): A centralized function to log all experiment parameters, metrics, and artifacts to MLflow, ensuring reproducibility.</li> </ul>"},{"location":"architecture/#3-data-flow-architecture","title":"3. Data Flow Architecture","text":"<p>The project follows distinct data flows for standard experiments and the RL pipeline.</p> <p>1. General Experiment Flow <pre><code>CLI Arguments \u2192 Main Orchestrator \u2192 Dataset Loading \u2192 Data Manipulation (Privacy/Personalization) \u2192 Algorithm Training &amp; Prediction \u2192 Evaluation \u2192 MLflow Logging\n</code></pre></p> <p>2. RL Pipeline Flow <pre><code>Raw DataFrame \u2192 KG Preprocessing \u2192 TransE Embedding Training \u2192 Agent Policy Training \u2192 Beam Search Inference \u2192 Path-based Recommendations \u2192 Evaluation\n</code></pre></p>"},{"location":"architecture/#4-key-design-patterns","title":"4. Key Design Patterns","text":"<p>The project employs several key design patterns to promote modularity and robustness.</p> <ul> <li>Modular Algorithm Interface: All main algorithm loops (<code>cf_experiment_loop</code>, etc.) share a consistent function signature, allowing the main orchestrator to call them interchangeably.</li> <li>Configuration-Driven Experiments: Experiments are defined in a central list of dictionaries (<code>EXPERIMENT_CONFIGS</code>), making it easy to add or modify test runs without changing the core logic.</li> <li>Defensive Programming: Metric calculations are wrapped in <code>try...except</code> blocks to prevent a single failure from halting an entire experiment batch.</li> <li>Caching and Persistence: The RL pipeline extensively caches intermediate artifacts (processed data, knowledge graphs, trained embeddings) to speed up subsequent runs and debugging.</li> </ul>"},{"location":"citation/","title":"How to Cite This Work","text":"<p>This page provides standardized formats for citing the QPERA project, its associated Master's Thesis, and the foundational libraries it builds upon.</p>"},{"location":"citation/#1-primary-citation","title":"1. Primary Citation","text":"<p>If you use this project, its findings, or its code in your research, please cite the Master's Thesis.</p>"},{"location":"citation/#bibtex-format","title":"BibTeX Format","text":"<pre><code>@mastersthesis{podsadna_chwilkowski2025qpera,\n  title     = {Quality of Personalization, Explainability and Robustness of Recommendation Algorithms},\n  author    = {Podsadna, Julia and Chwi{\\l}kowski, Bartosz},\n  year      = {2025},\n  school    = {Poznan University of Technology},\n  address   = {Poznan, Poland},\n  supervisor= {Morzy, Miko{\\l}aj},\n  type      = {Master's Thesis},\n  note      = {Faculty of Computing and Telecommunications},\n  url       = {https://github.com/PUT-RecSys-Research/qpera-thesis}\n}\n</code></pre>"},{"location":"citation/#2-software-citation","title":"2. Software Citation","text":"<p>To cite the software implementation directly, you can use the following format.</p>"},{"location":"citation/#bibtex-format_1","title":"BibTeX Format","text":"<pre><code>@software{qpera_software_2025,\n  author    = {Podsadna, Julia and Chwi{\\l}kowski, Bartosz},\n  title     = {QPERA: A Project for Evaluating Quality, Personalization, Explainability, and Robustness of Recommendation Algorithms},\n  year      = {2025},\n  publisher = {GitHub},\n  version   = {1.0.0},\n  url       = {https://github.com/PUT-RecSys-Research/qpera-thesis},\n  license   = {MIT}\n  // TODO: When a Zenodo release is created, add the DOI here.\n  // doi    = {10.5281/zenodo.XXXXXXX}\n}\n</code></pre>"},{"location":"citation/#3-citing-foundational-works","title":"3. Citing Foundational Works","text":"<p>This project builds directly upon pioneering open-source libraries. We strongly encourage you to also cite their original papers and software to give proper credit to the foundational work.</p>"},{"location":"citation/#microsoft-recommenders","title":"Microsoft Recommenders","text":"<p>Used for the collaborative filtering and content-based filtering implementations.</p> <pre><code>@inproceedings{recommenders2019,\n  author    = {Graham, Scott and Min, Jun Ki and Wu, Tao and Soni, Anish},\n  title     = {Microsoft Recommenders: Tools to Accelerate Developing Recommender Systems},\n  year      = {2019},\n  booktitle = {Proceedings of the 13th ACM Conference on Recommender Systems (RecSys '19)},\n  pages     = {542--543},\n  publisher = {Association for Computing Machinery},\n  doi       = {10.1145/3298689.3346967}\n}\n</code></pre>"},{"location":"citation/#pgpr-reinforcement-learning","title":"PGPR (Reinforcement Learning)","text":"<p>The basis for our reinforcement learning and explainability implementation.</p> <pre><code>@inproceedings{xian2019pgpr,\n  author    = {Xian, Yikun and Fu, Zuohui and Muthukrishnan, S. and de Melo, Gerard and Zhang, Yongfeng},\n  title     = {Reinforcement Knowledge Graph Reasoning for Explainable Recommendation},\n  year      = {2019},\n  booktitle = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '19)},\n  pages     = {285--294},\n  publisher = {Association for Computing Machinery},\n  doi       = {10.1145/3331184.3331203}\n}\n</code></pre>"},{"location":"citation/#recmetrics","title":"Recmetrics","text":"<p>Used for calculating the <code>personalization</code> and <code>intra_list_similarity</code> metrics.</p> <pre><code>@software{recmetrics2020,\n  author    = {Longo, Claire},\n  title     = {Recmetrics: A library of metrics for evaluating recommender systems},\n  year      = {2020},\n  version   = {0.1.3},\n  publisher = {GitHub},\n  url       = {https://github.com/statisticianinstilettos/recmetrics}\n}\n</code></pre>"},{"location":"citation/#4-license","title":"4. License","text":"<p>This project is licensed under the MIT License. You are free to use, modify, and distribute the code, but you must include the original copyright notice and license file in any derivative works. Please see the LICENSE file for full details.</p>"},{"location":"contributing/","title":"Development Workflow","text":"<p>This document provides a practical guide for the development workflow used in the QPERA project. Its purpose is to ensure consistency and reproducibility for the authors and any future researchers building on this work.</p>"},{"location":"contributing/#1-development-environment-setup","title":"1. Development Environment Setup","text":""},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Conda/Miniconda</li> <li>Git</li> </ul>"},{"location":"contributing/#installation-steps","title":"Installation Steps","text":"<ol> <li> <p>Fork and Clone the Repository <pre><code># Fork the repository on GitHub, then clone your fork\ngit clone https://github.com/YOUR-USERNAME/qpera-thesis.git\ncd qpera-thesis\n\n# Add the original repository as the \"upstream\" remote\ngit remote add upstream https://github.com/PUT-RecSys-Research/qpera-thesis.git\n</code></pre></p> </li> <li> <p>Create and Activate the Environment <pre><code># Create the conda environment from the environment.yml file\nmake install\nconda activate qpera-env\n</code></pre></p> </li> <li> <p>Install the Project Package <pre><code># Install the qpera package in editable mode for development\nmake setup\n</code></pre></p> </li> </ol>"},{"location":"contributing/#2-core-development-workflow","title":"2. Core Development Workflow","text":""},{"location":"contributing/#branching","title":"Branching","text":"<p>All changes should be made in a feature branch to keep the <code>main</code> branch stable. <pre><code>git checkout -b feature/your-descriptive-branch-name\n</code></pre></p>"},{"location":"contributing/#code-quality","title":"Code Quality","text":"<p>We use <code>ruff</code> for fast linting and formatting. - Check for issues: <code>make lint</code> - Automatically format code: <code>make format</code></p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Before committing, run a small-scale experiment to ensure your changes haven't broken the pipeline. <pre><code># Run a quick test on the MovieLens dataset\npython -m qpera.main --algo CF --dataset movielens --rows 1000\n</code></pre></p>"},{"location":"contributing/#3-extending-the-project","title":"3. Extending the Project","text":"<p>This section provides a high-level overview of how to add new components.</p>"},{"location":"contributing/#adding-a-new-algorithm","title":"Adding a New Algorithm","text":"<ol> <li>Create a new file (e.g., <code>qpera/NEW_ALGORITHM.py</code>) with an experiment loop function that matches the signature of existing algorithms (like <code>cf_experiment_loop</code>).</li> <li>Implement the data loading, training, prediction, and evaluation logic.</li> <li>Register the new algorithm in the <code>EXPERIMENT_CONFIGS</code> list in <code>qpera/main.py</code>.</li> </ol>"},{"location":"contributing/#adding-a-new-metric","title":"Adding a New Metric","text":"<ol> <li>Add the metric calculation function to <code>qpera/metrics.py</code>.</li> <li>Integrate the new metric into the evaluation section of the relevant algorithm loops (e.g., in <code>qpera/CF.py</code>).</li> </ol>"},{"location":"contributing/#adding-a-new-dataset","title":"Adding a New Dataset","text":"<ol> <li>Create a new loader class in <code>qpera/datasets_loader.py</code> that inherits from <code>BaseDatasetLoader</code>.</li> <li>Implement the <code>merge_datasets</code> method for your specific data source.</li> <li>Register the new loader in the <code>dataset_loaders</code> dictionary within the <code>loader</code> function.</li> </ol>"},{"location":"contributing/#4-documentation","title":"4. Documentation","text":"<p>The documentation is built with MkDocs. To preview your changes locally: <pre><code># Serve the documentation at http://127.0.0.1:8000\nmkdocs serve\n</code></pre></p>"},{"location":"contributing/#5-contact","title":"5. Contact","text":"<p>For questions about the project, please contact the authors: - Julia Podsadna  - Bartosz Chwi\u0142kowski - Supervisor: Prof. Miko\u0142aj Morzy</p>"},{"location":"datasets/","title":"Datasets Guide","text":"<p>This document provides a comprehensive guide to the datasets used in the QPERA project, including setup, processing details, and instructions for adding new data sources.</p>"},{"location":"datasets/#overview","title":"Overview","text":"<p>This project uses three main datasets to evaluate recommendation algorithms across different domains.</p> Dataset Domain Raw Size Users Items Ratings Kaggle Source MovieLens Movies ~20M ~138K ~27K ~20M <code>grouplens/movielens-20m-dataset</code> Amazon Sales E-commerce ~1.4M ~1M ~200K Generated <code>karkavelrajaj/amazon-sales-dataset</code> Post Recs Social Media ~150K ~10K ~50K Generated <code>vatsalparsaniya/post-pecommendation</code>"},{"location":"datasets/#1-automatic-download-setup","title":"1. Automatic Download &amp; Setup","text":""},{"location":"datasets/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kaggle Account: You need a Kaggle account to download the datasets.</li> <li>Kaggle API Token: Download your <code>kaggle.json</code> file from your Kaggle account page.</li> </ul>"},{"location":"datasets/#setup-steps","title":"Setup Steps","text":"<ol> <li> <p>Install the Kaggle API client:     <pre><code>pip install kaggle\n</code></pre></p> </li> <li> <p>Auto Configure Kaggle Credentials:     Places your <code>kaggle.json</code> file in the <code>~/.kaggle/</code> directory.     <pre><code>make kaggle-autoconfig\n</code></pre></p> </li> <li> <p>Download All Datasets:     Use the <code>Makefile</code> command to download and extract all required datasets automatically.     <pre><code>make check-datasets\n</code></pre>     This command checks for existing files and only downloads what is missing.</p> </li> </ol>"},{"location":"datasets/#2-dataset-details-processing","title":"2. Dataset Details &amp; Processing","text":"<p>The project uses a unified loading system (<code>qpera/datasets_loader.py</code>) that standardizes column names and applies specific preprocessing for each dataset.</p>"},{"location":"datasets/#movielens","title":"MovieLens","text":"<ul> <li>Source: <code>grouplens/movielens-20m-dataset</code></li> <li>Raw Files: <code>rating.csv</code>, <code>movie.csv</code>, <code>tag.csv</code></li> <li>Key Processing Steps:<ul> <li>Columns are mapped to standard names (e.g., <code>movieId</code> -&gt; <code>itemID</code>).</li> <li>Genres are converted from <code>Action|Adventure</code> to <code>Action Adventure</code>.</li> <li>Timestamps are converted to a standard Unix format.</li> <li>Duplicate user-item interactions are removed.</li> </ul> </li> </ul>"},{"location":"datasets/#amazon-sales","title":"Amazon Sales","text":"<ul> <li>Source: <code>karkavelrajaj/amazon-sales-dataset</code></li> <li>Raw Files: <code>amazon.csv</code></li> <li>Key Processing Steps:<ul> <li>Columns are mapped (e.g., <code>product_id</code> -&gt; <code>itemID</code>).</li> <li><code>category</code> and <code>about_product</code> are combined to create a <code>genres</code> field.</li> <li>Missing timestamps are generated based on user interaction order.</li> <li>Unnecessary columns (e.g., <code>discounted_price</code>, <code>img_link</code>) are dropped.</li> </ul> </li> </ul>"},{"location":"datasets/#post-recommendations","title":"Post Recommendations","text":"<ul> <li>Source: <code>vatsalparsaniya/post-pecommendation</code></li> <li>Raw Files: <code>user_data.csv</code>, <code>view_data.csv</code>, <code>post_data.csv</code></li> <li>Key Processing Steps:<ul> <li>Rating Generation: This dataset lacks explicit ratings. They are generated based on user interaction frequency with different post categories.</li> <li>Columns are mapped (e.g., <code>post_id</code> -&gt; <code>itemID</code>, <code>category</code> -&gt; <code>genres</code>).</li> <li>User, post, and view data are merged into a single interaction table.</li> </ul> </li> </ul>"},{"location":"datasets/#3-data-loading-caching","title":"3. Data Loading &amp; Caching","text":"<p>The <code>loader</code> function in <code>qpera/datasets_loader.py</code> provides a single, consistent interface for accessing all datasets.</p>"},{"location":"datasets/#caching-mechanism","title":"Caching Mechanism","text":"<p>To speed up repeated experiments, the loader uses a caching system: - On the first load, raw files are processed and saved as a single <code>merge_file.csv</code> in <code>qpera/datasets/&lt;DatasetName&gt;/</code>. - Subsequent loads read directly from this cached file. - If you specify <code>num_rows</code>, a separate cached file is created (e.g., <code>merge_file_r14000_s42.csv</code>), allowing you to work with smaller subsets without reprocessing.</p>"},{"location":"datasets/#usage-example","title":"Usage Example","text":"<pre><code>from qpera.datasets_loader import loader\n\n# Load the full, cached MovieLens dataset\ndata = loader(\"movielens\")\n\n# Load a 14,000-row subset for faster RL experiments\ndata_subset = loader(\"movielens\", num_rows=14000, seed=42)\n</code></pre>"},{"location":"datasets/#4-reinforcement-learning-data-pipeline","title":"4. Reinforcement Learning Data Pipeline","text":"<p>The Reinforcement Learning (RL) algorithm uses a separate, more complex data pipeline. - Input: The same processed data from the <code>loader</code>. - Process: It builds a knowledge graph by extracting entities (users, items, genres) and relations (watched, belongs_to). - Output &amp; Cache: The processed graph, embeddings, and labels are cached as <code>.pkl</code> files in the <code>qpera/rl_tmp/&lt;DatasetName&gt;/</code> directory. This cache is separate from the main dataset cache.</p>"},{"location":"datasets/#5-adding-a-new-dataset","title":"5. Adding a New Dataset","text":"<p>To integrate a new dataset into the project, follow these steps:</p> <ol> <li>Create a Loader Class: In <code>qpera/datasets_loader.py</code>, create a new class that inherits from <code>BaseDatasetLoader</code>. Implement the <code>_check_local_files_exist</code> and <code>merge_datasets</code> methods to handle your specific files and processing logic.</li> <li>Register the Loader: Add your new class to the <code>dataset_loaders</code> dictionary inside the <code>loader</code> function.</li> <li>Add Downloader Support (Optional): In <code>qpera/datasets_downloader.py</code>, add your dataset's information to the <code>DATASET_CONFIG</code> dictionary to enable automatic downloads with <code>make check-datasets</code>.</li> <li>Add RL Support (Optional): If the dataset should be used with the RL algorithm, update the path dictionaries (<code>DATASET_DIR</code>, <code>TMP_DIR</code>, <code>LABELS</code>) in <code>qpera/rl_utils.py</code>.</li> </ol>"},{"location":"datasets/#6-troubleshooting","title":"6. Troubleshooting","text":"<ul> <li><code>FileNotFoundError</code>: Ensure you have run <code>make check-datasets</code> to download all raw data.</li> <li>Kaggle API <code>401 Unauthorized</code>: Verify your <code>~/.kaggle/kaggle.json</code> file is correctly placed and has the right permissions (<code>chmod 600</code>).</li> <li>RL Pipeline Errors: If you encounter issues with the RL pipeline, try clearing its specific cache by deleting the <code>qpera/rl_tmp/&lt;DatasetName&gt;</code> directory and re-running the experiment.</li> </ul>"},{"location":"experiments/","title":"Running Experiments","text":"<p>This guide explains how to run and configure experiments with different recommendation algorithms in the QPERA project.</p>"},{"location":"experiments/#1-quick-commands","title":"1. Quick Commands","text":""},{"location":"experiments/#full-experiment-suite","title":"Full Experiment Suite","text":"<p>To run all predefined experiments across all datasets and scenarios: <pre><code>make run-all\n</code></pre></p>"},{"location":"experiments/#viewing-results","title":"Viewing Results","text":"<p>All results are tracked with MLflow. Start the UI to view them: <pre><code>make run-mlflow\n</code></pre> Then, navigate to <code>http://127.0.0.1:8080</code> in your browser.</p>"},{"location":"experiments/#2-experiment-configuration","title":"2. Experiment Configuration","text":"<p>This project uses a configuration-driven approach. Instead of passing many command-line arguments, experiments are defined in a list within <code>qpera/main.py</code>.</p>"},{"location":"experiments/#predefined-experiment-matrix","title":"Predefined Experiment Matrix","text":"<p>The <code>EXPERIMENT_CONFIGS</code> list defines the core combinations of algorithms and datasets to be tested: <pre><code># Located in qpera/main.py\nEXPERIMENT_CONFIGS = [\n    {\"algo\": \"CBF\", \"dataset\": \"movielens\", \"rows\": 14000},\n    {\"algo\": \"CF\", \"dataset\": \"movielens\", \"rows\": 14000},\n    {\"algo\": \"RL\", \"dataset\": \"movielens\", \"rows\": 14000},\n    # ... and more combinations for amazonsales and postrecommendations\n]\n</code></pre></p>"},{"location":"experiments/#experiment-scenarios","title":"Experiment Scenarios","text":"<p>For each entry in the matrix, the main script runs three types of scenarios:</p> <ol> <li>Clear (Baseline): The algorithm runs on the original, unmodified data.</li> <li>Privacy: Metadata is progressively hidden to test algorithm robustness. This is done by hiding a fraction (<code>0.1</code>, <code>0.25</code>, <code>0.5</code>, <code>0.8</code>) of values in the <code>title</code> and <code>genres</code> columns.</li> <li>Personalization: User preferences are shifted by replacing a fraction of their interactions with globally popular items to test how personalization is affected.</li> </ol>"},{"location":"experiments/#3-available-algorithms","title":"3. Available Algorithms","text":""},{"location":"experiments/#collaborative-filtering-cf","title":"Collaborative Filtering (CF)","text":"<ul> <li>Implementation: Cornac BPR (Bayesian Personalized Ranking).</li> <li>Key Hyperparameters: <code>k=100</code> (factors), <code>max_iter=100</code>, <code>learning_rate=0.01</code>.</li> <li>Best for: Datasets with strong user-item interaction signals.</li> </ul>"},{"location":"experiments/#content-based-filtering-cbf","title":"Content-Based Filtering (CBF)","text":"<ul> <li>Implementation: A custom <code>TfidfRecommender</code> using item metadata.</li> <li>Features: Primarily uses the <code>genres</code> column for TF-IDF vectorization and cosine similarity.</li> <li>Best for: Cold-start scenarios and datasets with rich item descriptions.</li> </ul>"},{"location":"experiments/#reinforcement-learning-rl","title":"Reinforcement Learning (RL)","text":"<ul> <li>Implementation: A PGPR-based agent that navigates a knowledge graph.</li> <li>Key Components:<ul> <li>Knowledge Graph: Built from users, items, and their attributes.</li> <li>TransE Embeddings: Learns representations for entities and relations.</li> <li>Actor-Critic Agent: Learns a policy to find recommendation paths.</li> </ul> </li> <li>Best for: Generating explainable, sequential recommendations.</li> <li>Note: Requires a multi-stage pipeline and is computationally intensive (GPU recommended).</li> </ul>"},{"location":"experiments/#4-evaluation-metrics","title":"4. Evaluation Metrics","text":"<p>The project computes a comprehensive set of metrics, all logged to MLflow.</p> <ul> <li>Accuracy &amp; Ranking: <code>precision_at_k</code>, <code>recall_at_k</code>, <code>ndcg_at_k</code>, <code>mrr</code>, <code>mae</code>, <code>rmse</code>.</li> <li>Coverage &amp; Diversity: <code>user_coverage</code>, <code>item_coverage</code>, <code>personalization</code>, <code>intra_list_similarity</code>.</li> <li>Robustness: All metrics are calculated in <code>try...except</code> blocks to ensure that a failure in one metric does not stop the entire experiment.</li> </ul>"},{"location":"experiments/#5-reinforcement-learning-pipeline","title":"5. Reinforcement Learning Pipeline","text":"<p>The RL algorithm follows a distinct, multi-stage pipeline orchestrated by <code>qpera/RL.py</code>.</p> <ol> <li>Preprocessing: Extracts entities and relations from the raw data to build a knowledge graph structure.</li> <li>TransE Training: Trains a TransE model on the graph to learn embeddings for all entities and relations.</li> <li>Policy Training: Trains the Actor-Critic agent using PPO to learn how to navigate the graph.</li> <li>Inference: Uses a beam search algorithm to generate the top-k recommendation paths for each user in the test set.</li> </ol>"},{"location":"experiments/#6-caching-performance","title":"6. Caching &amp; Performance","text":"<p>To speed up development and repeated runs, the project uses two caching systems:</p> <ul> <li>Dataset Cache: Processed and merged datasets are saved in <code>qpera/datasets/&lt;DatasetName&gt;/</code>. Subsequent loads read from this cache.</li> <li>RL Artifact Cache: The RL pipeline saves its intermediate artifacts (knowledge graphs, embeddings, labels) to <code>qpera/rl_tmp/&lt;DatasetName&gt;/</code>.</li> </ul>"},{"location":"experiments/#7-troubleshooting","title":"7. Troubleshooting","text":""},{"location":"experiments/#mlflow-connection-issues","title":"MLflow Connection Issues","text":"<ul> <li>Problem: MLflow UI is not accessible or experiments are not logging.</li> <li>Solution:     <pre><code># Ensure the server is running\nmake run-mlflow\n\n# If it's corrupted, force-clear the local tracking data\nrm -rf mlruns/ mlflow.db\n</code></pre></li> </ul>"},{"location":"experiments/#rl-pipeline-fails","title":"RL Pipeline Fails","text":"<ul> <li>Problem: The RL experiment fails, often during training or graph creation.</li> <li>Solution: The RL cache can sometimes become corrupted. Clear it for the specific dataset and retry.     <pre><code># Example for MovieLens\nrm -rf qpera/rl_tmp/MovieLens/\nmake run-rl-movielens\n</code></pre></li> </ul>"},{"location":"experiments/#memory-errors","title":"Memory Errors","text":"<ul> <li>Problem: An experiment fails with an <code>OutOfMemoryError</code>.</li> <li>Solution: Reduce the dataset size for testing by editing the <code>rows</code> parameter in the <code>EXPERIMENT_CONFIGS</code> list in <code>qpera/main.py</code>.     <pre><code># Example of reducing Amazon Sales for a quick test\n{\"algo\": \"CF\", \"dataset\": \"amazonsales\", \"rows\": 5000},\n</code></pre></li> </ul>"},{"location":"getting-started/","title":"Getting Started with QPERA","text":"<p>This guide will help you set up the QPERA framework, download the necessary datasets, and run your first experiments.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Conda or Miniconda</li> <li>Git</li> <li>Kaggle account (for dataset downloads)</li> </ul>"},{"location":"getting-started/#quick-start-recommended","title":"\ud83d\ude80 Quick Start (Recommended)","text":"<p>This is the fastest way to get started. The <code>quickstart</code> command automates the entire setup, download, and execution process.</p> <ol> <li> <p>Clone the repository: <pre><code>git clone https://github.com/PUT-RecSys-Research/qpera-thesis.git\ncd qpera-thesis\n</code></pre></p> </li> <li> <p>Configure Kaggle API:     This project requires the Kaggle API for downloading datasets.</p> <ul> <li>Download your <code>kaggle.json</code> API token from your Kaggle account page.</li> <li>For automated setup instructions, run: <pre><code>kaggle-autoconfig\n</code></pre></li> </ul> </li> <li> <p>Run the Quick Start command:     This command will install the environment, download all datasets, and run the full experiment suite.     <pre><code>make quickstart\n</code></pre>     After completion, you can view the results in the MLflow UI.</p> </li> </ol>"},{"location":"getting-started/#step-by-step-installation","title":"\ud83d\udee0\ufe0f Step-by-Step Installation","text":"<p>For more control over the setup process, follow these steps.</p>"},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/PUT-RecSys-Research/qpera-thesis.git\ncd qpera-thesis\n</code></pre>"},{"location":"getting-started/#2-configure-kaggle-api","title":"2. Configure Kaggle API","text":"<ul> <li> <p>Download your Kaggle API key (<code>kaggle.json</code>) and place it in <code>~/.kaggle/</code>. For detailed instructions, run:</p> <p><pre><code>make kaggle-setup-help\n</code></pre> - Ensure your <code>kaggle.json</code> file is placed correctly.</p> </li> </ul>"},{"location":"getting-started/#3-environment-and-dependencies","title":"3. Environment and Dependencies","text":"<pre><code># Create the conda environment from the environment.yml file\nmake install\n\n# Activate the new environment\nconda activate ppera-env\n\n# Install the project package in editable mode\nmake setup\n</code></pre>"},{"location":"getting-started/#4-verify-installation","title":"4. Verify Installation","text":"<pre><code># Run this command to ensure the package is installed correctly\nmake check-env\n</code></pre>"},{"location":"getting-started/#5-download-datasets","title":"5. Download Datasets","text":"<p><pre><code># Download all datasets required for the experiments\nmake download-datasets\n</code></pre> For more details, see the Datasets Guide.</p>"},{"location":"getting-started/#running-experiments","title":"\ud83d\udd2c Running Experiments","text":"<p>Once the setup is complete, you can run experiments.</p>"},{"location":"getting-started/#run-the-full-suite","title":"Run the Full Suite","text":"<p>To execute all defined experiments across all datasets (Note: this will take a significant amount of time): <pre><code>make run-all\n</code></pre></p>"},{"location":"getting-started/#viewing-results","title":"\ud83d\udcca Viewing Results","text":"<p>The framework uses MLflow to track experiments.</p> <ol> <li>Start the MLflow UI: <pre><code>make run-mlflow\n</code></pre></li> <li>Open your browser:     Navigate to <code>http://127.0.0.1:8080</code> to view experiment runs, parameters, and metrics.</li> </ol>"},{"location":"getting-started/#whats-next","title":"\ud83d\uddfa\ufe0f What's Next?","text":"<ul> <li>Datasets Guide: Learn more about the datasets used in this project.</li> <li>Experiments Guide: See how to configure and customize experiment runs.</li> <li>Architecture Overview: Understand the project's code structure.</li> </ul>"},{"location":"getting-started/#support-questions","title":"\u2753 Support &amp; Questions","text":"<p>If you encounter any issues or have questions about the research, please feel free to:</p> <ul> <li>Open an Issue: For bugs or unexpected behavior, please open a new issue.</li> <li>Start a Discussion: For general questions or ideas, start a discussion.</li> <li>Contact the Authors: You can also reach out to the authors listed in the main README.md.</li> </ul>"},{"location":"results/","title":"Research Findings &amp; Contributions","text":"<p>Work in Progress</p> <p>This document outlines the structure for the final research findings. The content presented here is preliminary and will be updated as the project's experiments and analysis are completed.</p> <p>This document summarizes the key findings, contributions, and future directions of the QPERA Master's Thesis project.</p>"},{"location":"results/#1-abstract","title":"1. Abstract","text":"<p>Example: This research presents a comprehensive evaluation of three major recommendation algorithm families\u2014Collaborative Filtering (CF), Content-Based Filtering (CBF), and Reinforcement Learning (RL)\u2014across four critical dimensions: Quality, Personalization, Explainability, and Robustness (QPERA). Using a standardized evaluation pipeline, we analyze the trade-offs inherent in each approach...</p>"},{"location":"results/#2-key-findings","title":"2. Key Findings","text":"<p>This section summarizes the main results from our experiments. The full, detailed results for every run can be explored in the MLflow UI.</p>"},{"location":"results/#performance-summary","title":"Performance Summary","text":"Algorithm Personalization Privacy Robustness Explainability Accuracy Collaborative Filtering TBD TBD TBD TBD Content-Based TBD TBD TBD TBD Reinforcement Learning TBD TBD TBD TBD"},{"location":"results/#key-visualizations","title":"Key Visualizations","text":"<ul> <li> <p>Privacy vs. Utility Trade-off</p> <p></p> </li> <li> <p>Personalization Score Comparison</p> <p></p> </li> <li> <p>Precision-Recall Curves</p> <p></p> </li> </ul>"},{"location":"results/#analysis-by-research-question","title":"Analysis by Research Question","text":""},{"location":"results/#1-how-does-algorithm-performance-vary-across-different-datasets","title":"1. How does algorithm performance vary across different datasets?","text":"<ul> <li>Your analysis here... (e.g., \"On the MovieLens dataset, CF demonstrated the highest accuracy due to...\")</li> <li>Your analysis here... (e.g., \"In contrast, CBF excelled on the Amazon Sales dataset by leveraging...\")</li> </ul>"},{"location":"results/#2-what-is-the-trade-off-between-user-privacy-and-recommendation-utility","title":"2. What is the trade-off between user privacy and recommendation utility?","text":"<ul> <li>Your analysis here... (e.g., \"Our experiments showed that CF was surprisingly robust to metadata hiding, with performance degrading by only X%...\")</li> <li>Your analysis here... (e.g., \"The RL model was most sensitive, as its knowledge graph structure was directly impacted by...\")</li> </ul>"},{"location":"results/#3-how-does-the-quality-of-personalization-and-explainability-differ-between-algorithms","title":"3. How does the quality of personalization and explainability differ between algorithms?","text":"<ul> <li>Your analysis here... (e.g., \"In terms of personalization, the RL approach achieved the highest scores, generating more diverse recommendations...\")</li> <li>Your analysis here... (e.g., \"For explainability, CBF provided the most transparent feature-based explanations, while RL offered path-based reasoning...\")</li> </ul>"},{"location":"results/#3-contributions","title":"3. Contributions","text":"<ol> <li>A Unified Evaluation Framework: Your description here... (e.g., \"We designed and implemented a standardized pipeline to evaluate disparate recommendation algorithms...\")</li> <li>Empirical Trade-off Analysis: Your description here... (e.g., \"We provide quantitative evidence of the trade-offs between personalization, privacy, and explainability...\")</li> <li>Reproducible Research Artifact: Your description here... (e.g., \"The entire project is packaged for full reproducibility, serving as a valuable resource for future research.\")</li> </ol>"},{"location":"results/#4-future-work","title":"4. Future Work","text":"<ul> <li>Hybrid Models: Your suggestion here... (e.g., \"Develop hybrid algorithms that combine the strengths of different approaches...\")</li> <li>Advanced Explainability: Your suggestion here... (e.g., \"Integrate Large Language Models (LLMs) to translate path-based explanations into natural language...\")</li> <li>Fairness and Bias Audits: Your suggestion here... (e.g., \"Extend the evaluation framework to include metrics for fairness and bias...\")</li> </ul>"},{"location":"results/#5-how-to-cite-this-work","title":"5. How to Cite This Work","text":"<p>If you use this project in your research, please cite our work. For detailed citation formats, please see the Citation Guide.</p> <pre><code>@mastersthesis{podsadna_chwilkowski2025qpera,\n  title     = {Quality of Personalization, Explainability and Robustness of Recommendation Algorithms},\n  author    = {Podsadna, Julia and Chwi{\\l}kowski, Bartosz},\n  year      = {2025},\n  school    = {Poznan University of Technology},\n  url       = {https://github.com/PUT-RecSys-Research/qpera-thesis}\n}\n</code></pre>"}]}